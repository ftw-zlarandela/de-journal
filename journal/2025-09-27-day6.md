# Journal — 2025-09-13 — EXAMPLE DAY

## 1) What I learned (bullets, not prose)
- "The best errors are the ones you encounter today."
- Clarification from last lesson, normalization and dimensional modeling are not exclusive to each other. Both are actuually part of the process.
- Fact Table: IDs and all measurable values; Dimension Table: all descriptors per dimension
- Though we can add descriptors in the dimension table, it is better to add a separate dimension table for efficiency and cleanliness
- Prioritize what you're going to present, especially to a non-technical audience.

## 2) New vocabulary (define in your own words)
- 

## 3) Data Engineering mindset applied (what principles did I use?)
- Document everything!
- Always double check and validate when transitioning and ingesting.

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- In the Chinook assignment, I tried to converge several tables into the Track Dimension. Upon asking Sir Myk though, I should have instead created additional dimensions for the extra tables so as to make it more efficient and uniform.
- Thus, in cleaning the OULAD dataset, I tried to branch out the Student Info and Student Registration tables into several more dimension tables for repeating feature values, such as the Code Module, Code Presentation, and demographics.

## 5) Open questions (things I still don’t get)
- How to ingest the CSV file (Mikay did it for our group but I still want to learn how personally)

## 6) Next actions (small, doable steps)
- [ ] Meet with the group
- [ ] Explore the dataset more
- [ ] Finish assignment
- [ ] Learn how to create the pipeline from scratch
- [ ] Learn how to make a PK and FK for the assignment

## 7) Artifacts & links (code, queries, dashboards)
- https://analyse.kmi.open.ac.uk/open-dataset

---

### Mini reflection (3–5 sentences)
What surprised me? What would I do differently next time? What will I watch out for in production?

In this week's lesson, instead of learning new things, we were set to practice and validate what we learned last week and our assignment. Although most of what we have experienced were universal to all groups, there were things that we still failed to validate like the number of rows in raw and clean tables. It goes to show that we are all still in the learning process and that there is much to learn still. From this, I'll make sure to always validate the tables as a clean but incomplete or duplicated data is still a data that is not clean.


### BONUS: What is a meme that best describes what you feel or your learning today?

![Alt text](https://i.imgflip.com/yr4wv.jpg "data is THE backbone for any business decision")